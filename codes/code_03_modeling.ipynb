{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## LIBRARIES\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import multiprocessing\n",
    "import pickle\n",
    "import warnings\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import importlib\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## HELPER FUNCTIONS\n",
    "\n",
    "!pip install --upgrade dptools\n",
    "from dptools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## SETTINGS\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df_train = pd.read_csv('../data/prepared/df_v3.csv',      compression = 'gzip')\n",
    "df_test  = pd.read_csv('../data/prepared/df_test_v3.csv', compression = 'gzip')\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract target\n",
    "y = df_train['target']\n",
    "X = df_train.drop('target', axis = 1)\n",
    "del df_train\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# format test data\n",
    "X_test = df_test.drop('target', axis = 1)\n",
    "del df_test\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read items\n",
    "items = pd.read_csv('../data/prepared/items_v1.csv', compression = 'gzip')\n",
    "print(items.shape)\n",
    "\n",
    "# keep existing IDs\n",
    "items = items[items['itemID'].isin(X['itemID'].unique())]\n",
    "print(items.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### IMPORT EVALUATION FUNCTIUONS\n",
    "\n",
    "# profit function\n",
    "import functions\n",
    "importlib.reload(functions)\n",
    "from functions import profit, asymmetric_mse, postprocess_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### LIST RELEVANT FEATURES\n",
    "\n",
    "drop_feats = ['itemID', 'day_of_year']\n",
    "features = [var for var in X.columns if var not in drop_feats]\n",
    "print(len(features), ':', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### MODELING PARAMETERS\n",
    "\n",
    "# paritioning\n",
    "num_folds = 7   # no. CV folds\n",
    "test_days = 14  # no. days in the test set\n",
    "\n",
    "# settings\n",
    "cores = 4\n",
    "seed  = 23\n",
    "\n",
    "# rounds abd verbose\n",
    "stop_rounds = 10\n",
    "verbose     = 20\n",
    "\n",
    "# LGB parameters\n",
    "lgb_params = {\n",
    "    'boosting_type':    'gbdt',\n",
    "    'objective':        'regression',\n",
    "    'metrics':          'rmse',\n",
    "    'learning_rate':    0.1,\n",
    "    'n_estimators':     1000,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'feature_fraction': 0.8,\n",
    "    'lambda_l1':        0.1,\n",
    "    'lambda_l2':        0.1,\n",
    "    'silent':           True,\n",
    "    'verbosity':        -1,\n",
    "    'nthread' :         cores,\n",
    "    'random_state':     seed,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CROSS-VALIDATION LOOP\n",
    "\n",
    "# placeholders\n",
    "importances   = pd.DataFrame()\n",
    "preds_oof     = np.zeros((num_folds, items.shape[0]))\n",
    "reals_oof     = np.zeros((num_folds, items.shape[0]))\n",
    "preds_test    = np.zeros(items.shape[0])\n",
    "oof_rmse      = []\n",
    "oof_profit    = []\n",
    "oracle_profit = []\n",
    "clfs          = []\n",
    "train_idx     = []\n",
    "valid_idx     = []\n",
    "\n",
    "# objects\n",
    "train_days = X['day_of_year'].max() - 2*test_days - num_folds - X['day_of_year'].min()  # no. days in the train set\n",
    "time_start = time.time()\n",
    "\n",
    "# modeling loop\n",
    "for fold in range(num_folds):\n",
    "    \n",
    "    ##### PARTITIONING\n",
    "    \n",
    "    # validation dates\n",
    "    if fold == 0:\n",
    "        v_end = X['day_of_year'].max() - (test_days + 1)\n",
    "    else:\n",
    "        v_end = v_end - 1\n",
    "    v_start = v_end\n",
    "    \n",
    "    # training dates\n",
    "    t_end   = v_start - (test_days + 1)\n",
    "    t_start = t_end   - (train_days - 1)\n",
    "    \n",
    "    # extract index\n",
    "    train_idx.append(list(X[(X.day_of_year >= t_start) & (X.day_of_year <= t_end)].index))\n",
    "    valid_idx.append(list(X[(X.day_of_year >= v_start) & (X.day_of_year <= v_end)].index))   \n",
    "    \n",
    "    # extract samples\n",
    "    X_train, y_train = X.iloc[train_idx[fold]][features], y.iloc[train_idx[fold]]\n",
    "    X_valid, y_valid = X.iloc[valid_idx[fold]][features], y.iloc[valid_idx[fold]]\n",
    "    X_test = X_test[features]\n",
    "    \n",
    "    # information\n",
    "    print('-' * 65)\n",
    "    print('- train period days: {} -- {} (n = {})'.format(t_start, t_end, len(train_idx[fold])))\n",
    "    print('- valid period days: {} -- {} (n = {})'.format(v_start, v_end, len(valid_idx[fold])))\n",
    "    print('-' * 65)\n",
    "\n",
    "    \n",
    "    ##### MODELING\n",
    "       \n",
    "    # training\n",
    "    clf = lgb.LGBMRegressor(**lgb_params) \n",
    "    clf = clf.fit(X_train, y_train, \n",
    "                  eval_set              = [(X_train, y_train), (X_valid, y_valid)], \n",
    "                  eval_metric           = 'rmse', \n",
    "                  early_stopping_rounds = stop_rounds,\n",
    "                  verbose               = verbose)\n",
    "    clfs.append(clf)\n",
    "    \n",
    "    # inference\n",
    "    preds_oof[fold, :] = postprocess_preds(clf.predict(X_valid))\n",
    "    reals_oof[fold, :] = y_valid\n",
    "    preds_test += postprocess_preds(clf.predict(X_test)) / num_folds\n",
    "\n",
    "    # evaluation\n",
    "    oof_rmse.append(np.sqrt(mean_squared_error(y_valid, preds_oof[fold, :])))\n",
    "    oof_profit.append(profit(y_valid, preds_oof[fold, :], price = X.iloc[valid_idx[fold]]['simulationPrice'].values))\n",
    "    oracle_profit.append(profit(y_valid, y_valid,         price = X.iloc[valid_idx[fold]]['simulationPrice'].values))\n",
    "    \n",
    "    # feature importance\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df['Feature'] = features\n",
    "    fold_importance_df['Importance'] = clf.feature_importances_\n",
    "    fold_importance_df['Fold'] = fold + 1\n",
    "    importances = pd.concat([importances, fold_importance_df], axis = 0)\n",
    "    \n",
    "    # information\n",
    "    print('-' * 65)\n",
    "    print('FOLD {:d}/{:d}: RMSE = {:.2f}, PROFIT = {:.0f}'.format(fold + 1, \n",
    "                                                                  num_folds, \n",
    "                                                                  oof_rmse[fold], \n",
    "                                                                  oof_profit[fold]))\n",
    "    print('-' * 65)\n",
    "    print('')\n",
    "    \n",
    "\n",
    "# print performance\n",
    "print('')\n",
    "print('-' * 65)\n",
    "print('- AVERAGE RMSE: {:.2f}'.format(np.mean(oof_rmse)))\n",
    "print('- TOTAL PROFIT: {:.0f} ({:.2f}%)'.format(np.mean(oof_profit), 100 * np.mean(oof_profit) / np.mean(oracle_profit)))\n",
    "print('- RUNNING TIME: {:.2f} minutes'.format((time.time() - time_start) / 60))\n",
    "print('-' * 65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### EVALUATION\n",
    "\n",
    "fig = plt.figure(figsize = (12, 5))\n",
    "\n",
    "# residual plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(reals_oof.reshape(-1), preds_oof.reshape(-1))\n",
    "axis_lim = np.max([reals_oof.max(), preds_oof.max()])\n",
    "plt.ylim(top   = 1.02*axis_lim)\n",
    "plt.xlim(right = 1.02*axis_lim)\n",
    "plt.plot((0, axis_lim), (0, axis_lim), 'r--')\n",
    "plt.title('Residual Plot')\n",
    "plt.ylabel('Predicted demand')\n",
    "plt.xlabel('Actual demand')\n",
    "\n",
    "# feature importance\n",
    "plt.subplot(1, 2, 2)\n",
    "top_feats = 100\n",
    "cols = importances[['Feature', 'Importance']].groupby('Feature').mean().sort_values(by = 'Importance', ascending = False)[0:top_feats].index\n",
    "importance = importances.loc[importances.Feature.isin(cols)]\n",
    "sns.barplot(x = 'Importance', y = 'Feature', data = importance.sort_values(by = 'Importance', ascending = False), ci = 0)\n",
    "plt.title('Feature Importance')\n",
    "plt.tight_layout()\n",
    "\n",
    "# export\n",
    "plt.savefig('../model_performance.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### LOGS\n",
    "\n",
    "# model (RMSE, profit): description\n",
    "#\n",
    "# lgb_v1_df_v1 (102.49, -65.72%): lgb with 17 features\n",
    "# lgb_v2_df_v2 (78.08, 20.69%):   lgb with 18 features\n",
    "# lgb_v3_df_v3 (73.24, 20.22%):   lgb with 18 features\n",
    "# lgb_v4_df_v3 (73.37, 21.09%):   lgb with 18 features, train_days = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### SUBMISSION\n",
    "\n",
    "# model name\n",
    "name = 'lgb_v1_df_v4'\n",
    "sub_name = name + '_profit_' + str(int(np.round(np.mean(oof_profit))))\n",
    "\n",
    "# save OOF preds\n",
    "oof = np.stack((preds_oof, reals_oof))\n",
    "np.save('../oof_preds/' + sub_name + '.npy', oof)\n",
    "print(oof.shape)\n",
    "\n",
    "# save submissiion\n",
    "sub = pd.read_csv('../submissions/sample_submission.csv', sep = '|')\n",
    "sub['demandPrediction'] = postprocess_preds(preds_test)\n",
    "sub.to_csv('../submissions/sub_' + sub_name + '.csv', sep = '|', index = False)\n",
    "print(sub.shape)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
