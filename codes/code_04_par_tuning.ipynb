{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## LIBRARIES\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import multiprocessing\n",
    "import pickle\n",
    "import warnings\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import importlib\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, STATUS_OK, STATUS_FAIL, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## SETTINGS\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df_train = pd.read_csv('../data/prepared/df_v11.csv',      compression = 'gzip')\n",
    "df_test  = pd.read_csv('../data/prepared/df_test_v11.csv', compression = 'gzip')\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract target\n",
    "y = df_train['target']\n",
    "X = df_train.drop('target', axis = 1)\n",
    "del df_train\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# format test data\n",
    "X_test = df_test.drop('target', axis = 1)\n",
    "del df_test\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read items\n",
    "items = pd.read_csv('../data/prepared/items_v1.csv', compression = 'gzip')\n",
    "print(items.shape)\n",
    "\n",
    "# keep existing IDs\n",
    "items = items[items['itemID'].isin(X['itemID'].unique())]\n",
    "print(items.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### IMPORT EVALUATION FUNCTIUONS\n",
    "\n",
    "# profit function\n",
    "import functions\n",
    "importlib.reload(functions)\n",
    "from functions import asymmetric_mse, profit, postprocess_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### LIST RELEVANT FEATURES\n",
    "\n",
    "drop_feats = ['itemID', 'day_of_year'] + ['category1', 'category2', 'category3'] #+ list(X.filter(like = '_all_).columns\n",
    "features = [var for var in X.columns if var not in drop_feats]\n",
    "print(len(features), 'features')\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## MODELING PARAMETERS\n",
    "\n",
    "### TRAINING OPTIONS\n",
    "\n",
    "# target transformation\n",
    "target_transform = True\n",
    "\n",
    "# train on positive sales only\n",
    "train_on_positive = False\n",
    "\n",
    "\n",
    "### TUNING PARAMETERS\n",
    "\n",
    "# trials\n",
    "tuning_trials = 1000\n",
    "\n",
    "\n",
    "### CLASSIFIER PARAMETERS\n",
    "\n",
    "# boosting types\n",
    "boost_types = ['gbdt', 'goss']\n",
    "\n",
    "# training params\n",
    "lgb_reg_params = {    \n",
    "    'boosting_type':    hp.choice('boosting_type', boost_types),    \n",
    "    'objective':        'rmse',\n",
    "    'metrics':          'rmse',\n",
    "    'n_estimators':     10000,\n",
    "    'learning_rate':    hp.uniform('learning_rate',  0.0001, 0.3),\n",
    "    'max_depth':        hp.quniform('max_depth',          1,  16, 1),\n",
    "    'num_leaves':       hp.quniform('num_leaves',        10,  64, 1),\n",
    "    'bagging_fraction': hp.uniform('bagging_fraction',  0.3,   1),\n",
    "    'feature_fraction': hp.uniform('feature_fraction',  0.3,   1),\n",
    "    'lambda_l1':        hp.uniform('lambda_l1',           0,   1),\n",
    "    'lambda_l2':        hp.uniform('lambda_l2',           0,   1),\n",
    "    'silent':           True,\n",
    "    'verbosity':        -1,\n",
    "    'nthread' :         4,\n",
    "    'random_state':     77,\n",
    "}\n",
    "\n",
    "# evaluation params\n",
    "lgb_fit_params = {\n",
    "    'eval_metric':           'rmse',\n",
    "    'early_stopping_rounds': 100,\n",
    "    'verbose':               False,\n",
    "}\n",
    "\n",
    "# combine params\n",
    "lgb_space = dict()\n",
    "lgb_space['reg_params'] = lgb_reg_params\n",
    "lgb_space['fit_params'] = lgb_fit_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### HYPEROPT OBJECT\n",
    "\n",
    "class HPOpt(object):\n",
    "\n",
    "    # INIT\n",
    "    def __init__(self, x_train, x_test, y_train, y_test):\n",
    "        self.x_train = x_train\n",
    "        self.x_test  = x_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test  = y_test\n",
    "\n",
    "    # optimization process\n",
    "    def process(self, fn_name, space, trials, algo, max_evals):\n",
    "        fn = getattr(self, fn_name)\n",
    "        try:\n",
    "            result = fmin(fn        = fn, \n",
    "                          space     = space, \n",
    "                          algo      = algo, \n",
    "                          max_evals = max_evals, \n",
    "                          trials    = trials)\n",
    "        except Exception as e:\n",
    "            return {'status': STATUS_FAIL, 'exception': str(e)}\n",
    "        return result, trials\n",
    "    \n",
    "    \n",
    "    # LGBM INITIALIZATION\n",
    "    def lgb_reg(self, para):\n",
    "        para['reg_params']['max_depth']  = int(para['reg_params']['max_depth'])\n",
    "        para['reg_params']['num_leaves'] = int(para['reg_params']['num_leaves'])\n",
    "        reg = lgb.LGBMRegressor(**para['reg_params'])\n",
    "        return self.train_reg(reg, para)\n",
    "\n",
    "    \n",
    "    # TRAINING AND INFERENCE\n",
    "    def train_reg(self, reg, para):\n",
    "        \n",
    "        # fit LGB\n",
    "        reg.fit(self.x_train, self.y_train,\n",
    "                eval_set              = [(self.x_train, self.y_train), (self.x_test, self.y_test)], \n",
    "                sample_weight         = self.x_train['simulationPrice'].values,\n",
    "                eval_sample_weight    = [self.x_train['simulationPrice'].values, self.x_test['simulationPrice'].values],\n",
    "                **para['fit_params'])\n",
    "        \n",
    "        # inference\n",
    "        if target_transform:      \n",
    "            preds = postprocess_preds(reg.predict(self.x_test)**2)\n",
    "            reals = self.y_test**2\n",
    "        else:\n",
    "            preds = postprocess_preds(reg.predict(self.x_test))\n",
    "            reals = self.y_test\n",
    "        \n",
    "        # impute zeros\n",
    "        if train_on_positive:\n",
    "            preds[(self.x_test['order_sum_last_28'] == 0) & (self.x_test['promo_in_test'] == 0)] = 0\n",
    "\n",
    "        # compute loss [negative profit]\n",
    "        loss = np.round(-profit(reals, preds, price = self.x_test['simulationPrice'].values))\n",
    "                      \n",
    "        return {'loss': loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### DATA PARTITIONING\n",
    "\n",
    "# validation dates\n",
    "v_end   = 158          # 1 day before last validation fold in code_03_modeling\n",
    "v_start = v_end        # same as v_start\n",
    "\n",
    "# training dates\n",
    "t_start = 28           # first day in the data\n",
    "t_end   = v_start - 15 # validation day - two weeks\n",
    "\n",
    "# extract index\n",
    "train_idx = list(X[(X.day_of_year >= t_start) & (X.day_of_year <= t_end)].index)\n",
    "valid_idx = list(X[(X.day_of_year >= v_start) & (X.day_of_year <= v_end)].index)   \n",
    "\n",
    "# extract samples\n",
    "X_train, y_train = X.iloc[train_idx][features], y.iloc[train_idx]\n",
    "X_valid, y_valid = X.iloc[valid_idx][features], y.iloc[valid_idx]\n",
    "\n",
    "# keep positive cases\n",
    "if train_on_positive:\n",
    "    y_train = y_train.loc[(X_train['order_sum_last_28'] > 0) | (X_train['promo_in_test'] > 0)]\n",
    "    X_train = X_train.loc[(X_train['order_sum_last_28'] > 0) | (X_train['promo_in_test'] > 0)]\n",
    "    \n",
    "# target transformation\n",
    "if target_transform:\n",
    "    y_train = np.sqrt(y_train)\n",
    "    y_valid = np.sqrt(y_valid)\n",
    "\n",
    "# information\n",
    "print('-' * 65)\n",
    "print('- train period days: {} -- {} (n = {})'.format(t_start, t_end, len(train_idx)))\n",
    "print('- valid period days: {} -- {} (n = {})'.format(v_start, v_end, len(valid_idx)))\n",
    "print('-' * 65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### PARAMETER TUNING\n",
    "\n",
    "# instantiate objects\n",
    "hpo_obj = HPOpt(X_train, X_valid, y_train, y_valid)\n",
    "trials  = Trials() \n",
    "\n",
    "# perform tuning\n",
    "lgb_opt_params = hpo_obj.process(fn_name   = 'lgb_reg',\n",
    "                                 space     = lgb_space, \n",
    "                                 trials    = trials, \n",
    "                                 algo      = tpe.suggest, \n",
    "                                 max_evals = tuning_trials)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge best params to fixed params\n",
    "params = list(lgb_opt_params[0].keys())\n",
    "for par_id in range(len(params)):\n",
    "    lgb_reg_params[params[par_id]] = lgb_opt_params[0][params[par_id]]\n",
    "    \n",
    "# postprocess\n",
    "lgb_reg_params['boosting_type'] = boost_types[lgb_reg_params['boosting_type']]\n",
    "lgb_reg_params['max_depth']     = int(lgb_reg_params['max_depth'])\n",
    "lgb_reg_params['num_leaves']    = int(lgb_reg_params['num_leaves'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best params\n",
    "print('Best meta-parameters:')\n",
    "lgb_reg_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### LOSS DYNAMICS\n",
    "\n",
    "# extract loss\n",
    "y = [-x['loss'] for x in trials.results]\n",
    "\n",
    "# plot results\n",
    "fig = plt.figure(figsize = (15, 6))\n",
    "plt.plot(range(1, len(y) + 1), y)\n",
    "plt.ylabel('Profit')\n",
    "plt.xlabel('Iteration')\n",
    "plt.savefig('../lgb_meta_params_loss.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### PARAMETER PLOTS\n",
    "\n",
    "# plot relationships\n",
    "meta_params = list(trials.vals.keys())\n",
    "fig = plt.figure(figsize = (15, 15))\n",
    "for i in range(len(meta_params)):\n",
    "    \n",
    "    # extract values and loss\n",
    "    x = trials.vals[meta_params[i]]\n",
    "    y = [-x['loss'] for x in trials.results]\n",
    "        \n",
    "    # plot results\n",
    "    plt.subplot(4, 2, i + 1)\n",
    "    plt.scatter(x, y)\n",
    "    plt.xlabel(meta_params[i])\n",
    "    if (i == 0) | (i == 3):\n",
    "        plt.ylabel('Profit')\n",
    "    \n",
    "# export PDF\n",
    "plt.savefig('../lgb_meta_params_plots.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export dictionary\n",
    "par_file = open('../lgb_meta_params.pkl', 'wb')\n",
    "pickle.dump(lgb_reg_params, par_file)\n",
    "par_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
