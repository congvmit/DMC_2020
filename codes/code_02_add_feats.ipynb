{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## LIBRARIES\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import multiprocessing\n",
    "import pickle\n",
    "import warnings\n",
    "import gc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## HELPER FUNCTIONS\n",
    "\n",
    "!pip install --upgrade dptools\n",
    "from dptools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## SETTINGS\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "orders = pd.read_csv('../data/prepared/orders_v1.csv', compression = 'gzip')\n",
    "items  = pd.read_csv('../data/prepared/items_v1.csv',  compression = 'gzip')\n",
    "print(orders.shape)\n",
    "print(items.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dates\n",
    "orders['time']       = pd.to_datetime(orders['time'].astype('str'),       infer_datetime_format = True)\n",
    "items['promotion_0'] = pd.to_datetime(items['promotion_0'].astype('str'), infer_datetime_format = True)\n",
    "items['promotion_1'] = pd.to_datetime(items['promotion_1'].astype('str'), infer_datetime_format = True)\n",
    "items['promotion_2'] = pd.to_datetime(items['promotion_2'].astype('str'), infer_datetime_format = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADD FEATURES: ITEMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price ratio\n",
    "items['recommended_simulation_price_ratio'] = items['simulationPrice'] / items['recommendedRetailPrice']\n",
    "items['recommended_simulation_price_ratio'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detailed item category\n",
    "items['category'] = items['category1'].astype(str) + items['category2'].astype(str) + items['category3'].astype(str)\n",
    "items['category'] = items['category'].astype(int)\n",
    "items['category'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer rating ratio per manufacturer\n",
    "rating_manufacturer = items.groupby('manufacturer')['customerRating'].agg('mean').reset_index()\n",
    "rating_manufacturer.columns = ['manufacturer', 'mean_customerRating_manufacturer']\n",
    "items = items.merge(rating_manufacturer, how = 'left', on = 'manufacturer')\n",
    "items['customerRating_manufacturer_ratio'] = items['customerRating'] / items['mean_customerRating_manufacturer']\n",
    "del items['mean_customerRating_manufacturer']\n",
    "items['customerRating_manufacturer_ratio'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer rating ratio per category\n",
    "rating_category = items.groupby('category')['customerRating'].agg('mean').reset_index()\n",
    "rating_category.columns = ['category', 'mean_customerRating_category']\n",
    "items = items.merge(rating_category, how = 'left', on = 'category')\n",
    "items['customerRating_category_ratio'] = items['customerRating'] / items['mean_customerRating_category']\n",
    "del items['mean_customerRating_category']\n",
    "items['customerRating_category_ratio'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADD FEATURES: ORDERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total orders\n",
    "print(orders['order'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### AGGREGATE ORDERS BY DAY\n",
    "\n",
    "# aggregation\n",
    "orders['day_of_year'] = orders['time'].dt.dayofyear\n",
    "orders_price = orders.groupby(['itemID', 'day_of_year'])['salesPrice'].agg('mean').reset_index()\n",
    "orders = orders.groupby(['itemID', 'day_of_year'])['order'].agg('sum').reset_index()\n",
    "orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check total orders\n",
    "print(orders['order'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ADD MISSING INPUTS [ORDERS]\n",
    "\n",
    "# add items that were never sold before\n",
    "missing_itemIDs = set(items['itemID'].unique()) - set(orders['itemID'].unique())\n",
    "missing_rows = pd.DataFrame({'itemID':     list(missing_itemIDs), \n",
    "                            'day_of_year': np.ones(len(missing_itemIDs)).astype('int'), \n",
    "                            'order':       np.zeros(len(missing_itemIDs)).astype('int')})\n",
    "orders = pd.concat([orders, missing_rows], axis = 0)\n",
    "print(orders.shape)\n",
    "\n",
    "# add zeros for days with no transactions\n",
    "agg_orders = orders.groupby(['itemID', 'day_of_year']).order.unique().unstack('day_of_year').stack('day_of_year', dropna = False)\n",
    "agg_orders = agg_orders.reset_index()\n",
    "agg_orders.columns = ['itemID', 'day_of_year', 'order']\n",
    "agg_orders['order'].fillna(0, inplace = True)\n",
    "agg_orders['order'] = agg_orders['order'].astype(int)\n",
    "print(agg_orders.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ADD MISSING INPUTS [PRICES]\n",
    "\n",
    "# add items that were never sold before\n",
    "missing_rows = pd.DataFrame({'itemID':     list(missing_itemIDs), \n",
    "                            'day_of_year': np.ones(len(missing_itemIDs)).astype('int'), \n",
    "                            'salesPrice':  np.zeros(len(missing_itemIDs)).astype('int')})\n",
    "orders_price = pd.concat([orders_price, missing_rows], axis = 0)\n",
    "print(orders_price.shape)\n",
    "\n",
    "# add zeros for days with no transactions\n",
    "agg_orders_price = orders_price.groupby(['itemID', 'day_of_year']).salesPrice.unique().unstack('day_of_year').stack('day_of_year', dropna = False)\n",
    "agg_orders_price = agg_orders_price.reset_index()\n",
    "agg_orders_price.columns = ['itemID', 'day_of_year', 'salesPrice']\n",
    "agg_orders_price['salesPrice'].fillna(0, inplace = True)\n",
    "agg_orders_price['salesPrice'] = agg_orders_price['salesPrice'].astype(int)\n",
    "agg_orders_price['salesPrice'][agg_orders_price['salesPrice'] == 0] = np.nan\n",
    "print(agg_orders_price.shape)\n",
    "\n",
    "# fill missing prices for dates with no orders\n",
    "agg_orders_price['salesPrice'] = agg_orders_price.groupby(['itemID']).salesPrice.fillna(method = 'ffill')\n",
    "agg_orders_price['salesPrice'] = agg_orders_price.groupby(['itemID']).salesPrice.fillna(method = 'bfill')\n",
    "agg_orders_price = agg_orders_price.merge(items[['itemID', 'simulationPrice']], how = 'left', on = 'itemID')\n",
    "agg_orders_price['salesPrice'][agg_orders_price['salesPrice'].isnull()] = agg_orders_price['simulationPrice'][agg_orders_price['salesPrice'].isnull()]\n",
    "del agg_orders_price['simulationPrice']\n",
    "\n",
    "# merge prices to orders\n",
    "agg_orders = agg_orders.merge(agg_orders_price, how = 'left', on = ['itemID', 'day_of_year'])\n",
    "print(agg_orders.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FIND PROMOTION DAYS\n",
    "\n",
    "# documentation says that we have to manually mark promotion days in the training period\n",
    "# without marking, predictions are difficult because orders in some daye explode without apparent reason\n",
    "# we need to be very careful with threshold and rely on visuzal analysis and/or better metric to mark promos\n",
    "# I started with treating promotions as days when the number of orders for a given item exceeds 90th percentile\n",
    "# now I am trying to use a smarte technique using find_peaks() and specifying height and prominence\n",
    "\n",
    "# computations\n",
    "agg_orders['promotion'] = 0\n",
    "for itemID in tqdm(agg_orders['itemID'].unique()):\n",
    "    '''\n",
    "    # using quantiles\n",
    "    promo_quant = orders[orders['itemID'] == itemID]['order'].quantile(0.90)\n",
    "    orders.loc[(orders['itemID'] == itemID) & (orders['order'] >= promo_quant), 'promotion'] = 1\n",
    "    '''\n",
    "    # using find_peaks\n",
    "    promo    = np.zeros(len(agg_orders[agg_orders['itemID'] == itemID]))\n",
    "    avg      = agg_orders[(agg_orders['itemID'] == itemID)]['order'].median()\n",
    "    std      = agg_orders[(agg_orders['itemID'] == itemID)]['order'].std()\n",
    "    peaks, _ = find_peaks(np.append(agg_orders[agg_orders['itemID'] == itemID]['order'].values, avg), # append avg to enable marking last point as promo\n",
    "                          prominence = max(5, std),  # peak difference with neighbor points; max(5,std) to exclude cases when std is too small\n",
    "                          height     = avg + 2*std)  # minimal height of a peak\n",
    "    promo[peaks] = 1\n",
    "    agg_orders.loc[agg_orders['itemID'] == itemID, 'promotion'] = promo\n",
    "    \n",
    "# check total promotions\n",
    "print(agg_orders['promotion'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### COMPARE PROMOTIONS NUMBER\n",
    "\n",
    "# computations\n",
    "promo_in_train = (agg_orders['promotion'].sum() / agg_orders['day_of_year'].max()) / len(items)\n",
    "promo_in_test  = (3*len(items) - items.promotion_0.isnull().sum() - items.promotion_2.isnull().sum() - items.promotion_1.isnull().sum()) / 14 / len(items)\n",
    "\n",
    "# info\n",
    "print('Daily p(promotion) per item in train: {}'.format(np.round(promo_in_train, 4)))\n",
    "print('Daily p(promotion) per item in test:  {}'.format(np.round(promo_in_test , 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXAMPLE SALES PLOT\n",
    "\n",
    "# compute promo count\n",
    "promo_count = agg_orders.groupby('itemID')['promotion'].agg('sum').reset_index()\n",
    "promo_count = promo_count.sort_values('promotion').reset_index(drop = True)\n",
    "\n",
    "# plot some items\n",
    "item_plots = [0, 2000, 4000, 6000, 8000, 9000, 10000, 10100, 10200, 10300, 10400, 10462]\n",
    "fig = plt.figure(figsize = (16, 12))\n",
    "for i in range(len(item_plots)):\n",
    "    plt.subplot(3, 4, i + 1)\n",
    "    df = agg_orders[agg_orders.itemID == promo_count['itemID'][item_plots[i]]]\n",
    "    plt.scatter(df['day_of_year'], df['order'], c = df['promotion'])\n",
    "    plt.ylabel('Total Orders')\n",
    "    plt.xlabel('Day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### COMPUTING TARGETS AND FEATURES\n",
    "\n",
    "# parameters\n",
    "days_input  = [7, 14, 21, 28]\n",
    "days_target = 14\n",
    "\n",
    "# preparations\n",
    "day_first = np.max(days_input)\n",
    "day_last  = agg_orders['day_of_year'].max() - days_target\n",
    "orders    = None\n",
    "\n",
    "# merge manufacturer and category\n",
    "agg_orders = agg_orders.merge(items[['itemID', 'manufacturer']], how = 'left')\n",
    "agg_orders = agg_orders.merge(items[['itemID', 'category']],     how = 'left')\n",
    "\n",
    "\n",
    "# computations\n",
    "for day_of_year in tqdm(list(range(day_first, day_last)) + [agg_orders['day_of_year'].max()]):\n",
    "                \n",
    "\n",
    "    ###### VALIDAION: TARGET, PROMOTIONS, PRICES\n",
    "        \n",
    "    # day intervals\n",
    "    target_day_min = day_of_year + 1\n",
    "    target_day_max = day_of_year + days_target\n",
    "    \n",
    "    # compute target and promo: labeled data\n",
    "    if day_of_year < agg_orders['day_of_year'].max():\n",
    "        \n",
    "        # target and future promo\n",
    "        tmp_df = agg_orders[(agg_orders['day_of_year'] >= target_day_min) &\n",
    "                            (agg_orders['day_of_year'] <= target_day_max)\n",
    "                           ].groupby('itemID')['order', 'promotion'].agg('sum').reset_index()\n",
    "        tmp_df.columns = ['itemID', 'target', 'promo_in_test']\n",
    "        \n",
    "        # future price\n",
    "        tmp_df['mean_price_test'] = agg_orders[(agg_orders['day_of_year'] >= target_day_min) &\n",
    "                                               (agg_orders['day_of_year'] <= target_day_max)\n",
    "                                              ].groupby('itemID')['salesPrice'].agg('mean').reset_index()['salesPrice']\n",
    "        \n",
    "        # merge manufacturer and category\n",
    "        tmp_df = tmp_df.merge(items[['itemID', 'manufacturer', 'category']], how = 'left', on = 'itemID')\n",
    "        \n",
    "        # future price per manufacturer\n",
    "        tmp_df_manufacturer = agg_orders[(agg_orders['day_of_year'] >= target_day_min) &\n",
    "                                         (agg_orders['day_of_year'] <= target_day_max)\n",
    "                                         ].groupby('manufacturer')['salesPrice'].agg('mean').reset_index()\n",
    "        tmp_df_manufacturer.columns = ['manufacturer', 'mean_price_test_manufacturer']\n",
    "        tmp_df = tmp_df.merge(tmp_df_manufacturer, how = 'left', on = 'manufacturer')\n",
    "        \n",
    "        # future price per category\n",
    "        tmp_df_category = agg_orders[(agg_orders['day_of_year'] >= target_day_min) &\n",
    "                                     (agg_orders['day_of_year'] <= target_day_max)\n",
    "                                     ].groupby('category')['salesPrice'].agg('mean').reset_index()\n",
    "        tmp_df_category.columns = ['category', 'mean_price_test_category']\n",
    "        tmp_df = tmp_df.merge(tmp_df_category, how = 'left', on = 'category')\n",
    "        \n",
    "        # future promo per manufacturer\n",
    "        tmp_df_manufacturer = agg_orders[(agg_orders['day_of_year'] >= target_day_min) &\n",
    "                                         (agg_orders['day_of_year'] <= target_day_max)\n",
    "                                         ].groupby('manufacturer')['promotion'].agg('sum').reset_index()\n",
    "        tmp_df_manufacturer.columns = ['manufacturer', 'promo_in_test_manufacturer']\n",
    "        tmp_df = tmp_df.merge(tmp_df_manufacturer, how = 'left', on = 'manufacturer')\n",
    "\n",
    "        # future promo per category\n",
    "        tmp_df_category = agg_orders[(agg_orders['day_of_year'] >= target_day_min) &\n",
    "                                     (agg_orders['day_of_year'] <= target_day_max)\n",
    "                                     ].groupby('category')['promotion'].agg('sum').reset_index()\n",
    "        tmp_df_category.columns = ['category', 'promo_in_test_category']\n",
    "        tmp_df = tmp_df.merge(tmp_df_category, how = 'left', on = 'category')\n",
    "                \n",
    "        \n",
    "    # compute target and promo: unlabeled data\n",
    "    else:\n",
    "        \n",
    "        # placeholders\n",
    "        tmp_df = pd.DataFrame({'itemID':                     items.itemID,\n",
    "                               'target':                     np.nan,\n",
    "                               'promo_in_test':              np.nan,\n",
    "                               'mean_price_test':            items.simulationPrice,\n",
    "                               'manufacturer':               items.manufacturer,\n",
    "                               'category':                   items.category,\n",
    "                               'promo_in_test_manufacturer': np.nan,\n",
    "                               'promo_in_test_category':     np.nan})\n",
    "\n",
    "        \n",
    "    ###### TRAINING: LAG-BASED FEATURES\n",
    "            \n",
    "    # compute features\n",
    "    for day_input in days_input:\n",
    "        \n",
    "        # day intervals\n",
    "        input_day_min  = day_of_year - day_input + 1\n",
    "        input_day_max  = day_of_year\n",
    "    \n",
    "        # frequency, promo and price\n",
    "        tmp_df_input = agg_orders[(agg_orders['day_of_year'] >= input_day_min) &\n",
    "                                  (agg_orders['day_of_year'] <= input_day_max)\n",
    "                                 ].groupby('itemID')\n",
    "        tmp_df['order_sum_last_'   + str(day_input)] = tmp_df_input['order'].agg('sum').reset_index()['order']\n",
    "        tmp_df['order_count_last_' + str(day_input)] = tmp_df_input['order'].agg(lambda x: len(x[x > 0])).reset_index()['order']\n",
    "        tmp_df['promo_count_last_' + str(day_input)] = tmp_df_input['promotion'].agg('sum').reset_index()['promotion']\n",
    "        tmp_df['mean_price_last_'  + str(day_input)] = tmp_df_input['salesPrice'].agg('mean').reset_index()['salesPrice']\n",
    "\n",
    "        # frequency, promo per manufacturer\n",
    "        tmp_df_input = agg_orders[(agg_orders['day_of_year'] >= input_day_min) &\n",
    "                                  (agg_orders['day_of_year'] <= input_day_max)\n",
    "                                 ].groupby('manufacturer')\n",
    "        tmp_df_manufacturer = tmp_df_input['order'].agg('sum').reset_index()\n",
    "        tmp_df_manufacturer.columns = ['manufacturer', 'order_manufacturer_sum_last_' + str(day_input)]\n",
    "        tmp_df_manufacturer['order_manufacturer_count_last_' + str(day_input)] = tmp_df_input['order'].agg(lambda x: len(x[x > 0])).reset_index()['order']\n",
    "        tmp_df_manufacturer['promo_manufacturer_count_last_' + str(day_input)] = tmp_df_input['promotion'].agg('sum').reset_index()['promotion']\n",
    "        tmp_df = tmp_df.merge(tmp_df_manufacturer, how = 'left', on = 'manufacturer')\n",
    "    \n",
    "        # frequency, promo per category\n",
    "        tmp_df_input = agg_orders[(agg_orders['day_of_year'] >= input_day_min) &\n",
    "                                  (agg_orders['day_of_year'] <= input_day_max)\n",
    "                                 ].groupby('category')\n",
    "        tmp_df_category = tmp_df_input['order'].agg('sum').reset_index()\n",
    "        tmp_df_category.columns = ['category', 'order_category_sum_last_' + str(day_input)]       \n",
    "        tmp_df_category['order_category_count_last_' + str(day_input)] = tmp_df_input['order'].agg(lambda x: len(x[x > 0])).reset_index()['order']\n",
    "        tmp_df_category['promo_category_count_last_' + str(day_input)] = tmp_df_input['promotion'].agg('sum').reset_index()['promotion']\n",
    "        tmp_df = tmp_df.merge(tmp_df_category, how = 'left', on = 'category')\n",
    "\n",
    "        # frequency, promo per all items\n",
    "        tmp_df_input = agg_orders[(agg_orders['day_of_year'] >= input_day_min) &\n",
    "                                  (agg_orders['day_of_year'] <= input_day_max)]\n",
    "        tmp_df['order_all_sum_last_'   + str(day_input)] = tmp_df_input['order'].agg('sum')\n",
    "        tmp_df['order_all_count_last_' + str(day_input)] = tmp_df_input['order'].agg(lambda x: len(x[x > 0]))\n",
    "        tmp_df['promo_all_count_last_' + str(day_input)] = tmp_df_input['promotion'].agg('sum')\n",
    "        \n",
    "        # recency\n",
    "        if day_input == max(days_input):\n",
    "            tmp_df_input = agg_orders[(agg_orders['day_of_year'] >= input_day_min) &\n",
    "                                      (agg_orders['day_of_year'] <= input_day_max) &\n",
    "                                      (agg_orders['order'] > 0)\n",
    "                                     ].groupby('itemID')\n",
    "            tmp_df['days_since_last_order'] = (day_of_year - tmp_df_input['day_of_year'].agg('max')).reindex(tmp_df.itemID).reset_index()['day_of_year']\n",
    "            tmp_df['days_since_last_order'].fillna(day_input, inplace = True)\n",
    "            \n",
    "            \n",
    "            \n",
    "    ###### FINAL PREPARATIONS\n",
    "            \n",
    "    # add day of year\n",
    "    tmp_df.insert(1, column = 'day_of_year', value = day_of_year)\n",
    "        \n",
    "    # merge data\n",
    "    orders = pd.concat([orders, tmp_df], axis = 0)\n",
    "    \n",
    "    # drop manufacturer and category\n",
    "    del orders['manufacturer']\n",
    "    del orders['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### COMPUTE MEAN PRICE RATIOS\n",
    "\n",
    "print(orders.shape)\n",
    "price_vars = ['mean_price_last_7', 'mean_price_last_14', 'mean_price_last_21', 'mean_price_last_28']\n",
    "for var in price_vars:\n",
    "    orders['ratio_'              + str(var)] = orders['mean_price_test']              / orders[var]\n",
    "    orders['ratio_manufacturer_' + str(var)] = orders['mean_price_test_manufacturer'] / orders[var]\n",
    "    orders['ratio_category_'     + str(var)] = orders['mean_price_test_category']     / orders[var]\n",
    "print(orders.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example sales plot\n",
    "df = orders[orders.itemID == 1]\n",
    "plt.figure(figsize = (10, 5))\n",
    "plt.scatter(df['day_of_year'], df['target'], c = df['promo_in_test'])\n",
    "plt.title('itemID == 1')\n",
    "plt.ylabel('Target (orders in next 14 days)')\n",
    "plt.xlabel('Day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MERGE DATA SETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(orders.shape)\n",
    "print(items.shape)\n",
    "df = pd.merge(orders, items, on = 'itemID', how = 'left')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRACT TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition intro train and test\n",
    "df_train = df[df['day_of_year'] <  df['day_of_year'].max()]\n",
    "df_test  = df[df['day_of_year'] == df['day_of_year'].max()]\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## COMPUTE FEATURES FOR TEST DATA\n",
    "\n",
    "# add promotion info to test\n",
    "promo_vars = df_test.filter(like = 'promotion_').columns\n",
    "df_test['promo_in_test'] = 3 - df_test[promo_vars].isnull().sum(axis = 1)\n",
    "df_test['promo_in_test'].describe()\n",
    "\n",
    "\n",
    "### PROMO PER MANUFACTURER, CATEGORY\n",
    "\n",
    "del df_test['promo_in_test_manufacturer'], df_test['promo_in_test_category']\n",
    "\n",
    "# future promo per manufacturer\n",
    "tmp_df_manufacturer = df_test.groupby('manufacturer')['promo_in_test'].agg('sum').reset_index()\n",
    "tmp_df_manufacturer.columns = ['manufacturer', 'promo_in_test_manufacturer']\n",
    "df_test = df_test.merge(tmp_df_manufacturer, how = 'left', on = 'manufacturer')\n",
    "print(df_test.shape)\n",
    "\n",
    "# future promo per category\n",
    "tmp_df_category = df_test.groupby('category')['promo_in_test'].agg('sum').reset_index()\n",
    "tmp_df_category.columns = ['category', 'promo_in_test_category']\n",
    "df_test = df_test.merge(tmp_df_category, how = 'left', on = 'category')\n",
    "print(df_test.shape)\n",
    "\n",
    "\n",
    "### PRICE PER MANUFACTURER, CATEGORY\n",
    "\n",
    "del df_test['mean_price_test_manufacturer'], df_test['mean_price_test_category']\n",
    "\n",
    "# future price per manufacturer\n",
    "tmp_df_manufacturer = df_test.groupby('manufacturer')['mean_price_test'].agg('mean').reset_index()\n",
    "tmp_df_manufacturer.columns = ['manufacturer', 'mean_price_test_manufacturer']\n",
    "df_test = df_test.merge(tmp_df_manufacturer, how = 'left', on = 'manufacturer')\n",
    "print(df_test.shape)\n",
    "\n",
    "# future price per category\n",
    "tmp_df_category = df_test.groupby('category')['mean_price_test'].agg('mean').reset_index()\n",
    "tmp_df_category.columns = ['category', 'mean_price_test_category']\n",
    "df_test = df_test.merge(tmp_df_category, how = 'left', on = 'category')\n",
    "print(df_test.shape)\n",
    "\n",
    "\n",
    "### MEAN PRICE RATIOS\n",
    "\n",
    "for var in price_vars:\n",
    "    df_test['ratio_'              + str(var)] = df_test['mean_price_test']              / df_test[var]\n",
    "    df_test['ratio_manufacturer_' + str(var)] = df_test['mean_price_test_manufacturer'] / df_test[var]\n",
    "    df_test['ratio_category_'     + str(var)] = df_test['mean_price_test_category']     / df_test[var]\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop promotion dates\n",
    "df_test.drop(promo_vars,  axis = 1, inplace = True)\n",
    "df_train.drop(promo_vars, axis = 1, inplace = True)\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "\n",
    "# drop mean prices\n",
    "price_vars = price_vars + ['mean_price_test_manufacturer', 'mean_price_test_category']\n",
    "df_test.drop(price_vars,  axis = 1, inplace = True)\n",
    "df_train.drop(price_vars, axis = 1, inplace = True)\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### LOGS\n",
    "\n",
    "# data (shape): descriprion\n",
    "#\n",
    "# df_v1  (1357920, 23): first aggregated df version with 4x2 lagged frequency-based features [7,14,21,28 days]\n",
    "# df_v2  (1357920, 24): added promo_in_test feature using 0.9 percentile of item-specific demand\n",
    "# df_v3  (1433431, 21): added rows with missing itemIDs for items that were never sold during training period;\n",
    "#                      added test sample with NA target and promo_in_test feature\n",
    "#                      removed promotion_i features info from training data\n",
    "# df_v4  (1433431, 26): added promo_count features; added days_since_last_order with NA set to time horizon\n",
    "# df_v5  (1433431, 34): added all_promo_count and all_order_count features for aggregated stats on all items\n",
    "# df_v6  (1433431, 34): changed technique to identify promotions using find_peaks()\n",
    "# df_v7  (1433431, 38): changed names of \"order_all_...\" features, added sum of all orders\n",
    "# df_v8  (1433431, 50): added frequency and promo features per manufacturer\n",
    "# df_v9  (1433431, 54): added mean_price ratio features\n",
    "# df_v10 (1433431, 64): added all lag features for yesterday (day = 1)\n",
    "# df_v11 (1443894, 80): multiple changes in feature computation:\n",
    "#                        - fixed bug: test data is now correctly based on day 180 (was on 165 in previous versions)\n",
    "#                                     train data includes additional data previously assigned to test\n",
    "#                        - fixed bug: manufacturer-level features are now merged correctly to the DF\n",
    "#                        - added category-level features (category is combined of c1, c2 and c3)\n",
    "#                        - removed early lag features: days = [7,14,21,28]\n",
    "#                        - new item-level features: customer rating ratio per average per manufacture and category\n",
    "#                        - new price-based feature: ratio between the mean price in test and mean price in the past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data frame\n",
    "# save_csv_version() automatically adds version number to prevent overwriting\n",
    "save_csv_version('../data/prepared/df.csv',      df_train, index = False, compression = 'gzip')\n",
    "save_csv_version('../data/prepared/df_test.csv', df_test,  index = False, compression = 'gzip', min_version = 3)\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
